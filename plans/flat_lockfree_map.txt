
flat_lockfree_map

Flat:
|  Use only contiguous memory so that the serialized version is the normal version

Concurrent:
|  Lock free except when resizing
|  Do copy on write so that the reads don't stop 
|  Make mutex wait time for writes minimized
|

Hashing Insights:
|  With robin hood hashing multiple entries from the same key will be next to each other in memory
|  |  One data structure can be used for an unordered multi-map
|  Something about the fact that Ids are unique due to a reader keeping blocks from deletion, so versions aren't needed 
|  |  32 bit block indices can be used, they can be atomically swapped, and thus robin hood hashed


Reader Count:
|  Reader count needs to be incremented on two numbers before they are swapped
|  Use a deleted flag in an atomic struct and u32 : 31 for reader count
|  |  No, deleted doesn't need a flag, it just needs a special value


Template Arguments:
|  Use a variable template argument so that a arbitrary tuple can be returned?
|  |  How does a template allocator argument work if variable template arguments are used for values?
|  |  The problem is that you would mostly want the allocator to be an argument with a default value of the default allocator
|  |  Could the template argument be layed out as <key, value, allocator=default, values...>
|  |  Could the template arguments be side stepped by using a static make_ function instead of constructors
|


Return Values:
|  Use std::optional<> with operator[] ?
|  Use a custom struct that has operator bool() ?
|  |  Could have extra information such as how many values are in this key
|  Use operator() to get a specific value out of a key + tuple


Make untyped container with void* so that template bloat is minimal
|  Variable holds size in bytes
Use std::hash() ?
Save hash near reader count and pack them all together
Use power of 2 sizing


Does the number of readers need to be part of the block index in the new atomic lookup array?
|  If you lookup a block index, how do you know you haven't had it deleted from you?
|  Use 8 bits for readers, 24 bits for the index, and two special values for EMPTY and DELETED
|  Make START_SPECIALS = DELETED
|  Last thread out frees the block
|  |  Thread that sees readers == 1 && DELETED frees the block by setting the readers to 0 and the index to EMPTY 
|  |  thread should see readers == 0 and DELETED



If two indices are being swapped atomically, do they need the readers attached to them?
|  They couldn't be changed to DELETED or EMPTY underneath
|  They could however be changed to be completely different values with the same indices
|  While the swap could be done atomically, you don't know if that is what you want to do
|  |  Maybe there is a way for eventual consistency by checking before and after two indices are swapped
|  |  However this introduces the possibility of an inserted value blinking out of existence due to another thread seeing an EMPTY or DELETED slot too early
|  This means that the actual sequence is:
|  |  Readers need to be incremented
|  |  The hashes need to be checked to make sure that their positions need to be swapped
|  |  Swap the indices
|  |  Decrement the readers
|  This is all neccesary because an insertion needs to start from the first free slot and swap backwards until:
|  |  The hash lines up with it's natural slot (hash % slots) or ...
|  |  The element at one index less has the same hash
|  |  |  What if they have the same hash but not the same key? 
|  |  |  Whole other can of worms, maybe they should be compared with operator< etc.
|  


Value meta data:
|  Store the hash
|  Store the index in the meta data? - no need since you are literally reading from the index when you read the meta data - you have to have it saved as a variable on the stack locally already
|  Hash and what else since the size is constant?  
|  Does the hash need to be stored? 
|  |  Storing the hash could save time since robin hood hashing will be doing comparisons with the neighbor slots
|  Does the meta data need to be saved in a separate place?
|  Why was it done like that previously? Cache locality?
|  Should the hash and the key be stored together with the value stored separatly?

What happens if an index is deleted, cleaned up, then the same index is used again and moved to a different slot while another thread is reading?
|  If a Idx is moved around, it can still be searched for
|  If the readers is incremented, that val_idx can't be used again, so you know it is unique
|  Even if it is moved, you know that the key it contains can't change and thus the hash can't change
|  If the hash can't change, you can start from the natural/ideal slot position and search forward until you find the index you are looking for
|

Possibly need to make sure that when deleting a Idx in a slot, DELETED is set atomically, then separately the readers are decremented, and only if the deleting thread gets back readers == 1 and DELETED is it responsible for freeing the block
|  If readers == 1 and DELETED the Idx needs to be successfully compare and swapped for readers == 0 and DELETED before freeing the block
|  Need to increment the readers before marking for deletion, so that there isn't confusion about what thread needs to delete 
|  |  This sets up the case where a thread can get be the only one to comapre and swap from readers==1 && DELETED to readers==0 && DELETED
|


How to iterate through multiple values for a single key?
|  On step forward do multiple steps
|  |  Increment the reader count
|  |  Read the key and value into the iterator
|  |  Decrement the reader count
|  |  On dereference, return the value that was already read
|  |  If no value is found, set the iterator to == end()
|


Have to make room for the block list
|  A block list header
|  A u32 for each index
|  Should the current list index eventually be padded to be on its own cache line to negate false sharing?
| 


Capacity and the concurrent list
|  Might need to keep track of capacity atomically with the concurrent list
|  Instead of version in the head, a u32 can be used for capacity 
|  Keeping track of capacity is important so that a resize can be done before reaching the end of the list


