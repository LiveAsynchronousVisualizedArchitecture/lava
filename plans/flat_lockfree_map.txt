
flat_lockfree_map

Flat:
|  Use only contiguous memory so that the serialized version is the normal version

Concurrent:
|  Lock free except when resizing
|  Do copy on write so that the reads don't stop 
|  Make mutex wait time for writes minimized
|

Hashing Insights:
|  With robin hood hashing multiple entries from the same key will be next to each other in memory
|  |  One data structure can be used for an unordered multi-map
|  Something about the fact that Ids are unique due to a reader keeping blocks from deletion, so versions aren't needed 
|  |  32 bit block indices can be used, they can be atomically swapped, and thus robin hood hashed


Reader Count:
|  Reader count needs to be incremented on two numbers before they are swapped
|  Use a deleted flag in an atomic struct and u32 : 31 for reader count
|  |  No, deleted doesn't need a flag, it just needs a special value


Template Arguments:
|  Use a variable template argument so that a arbitrary tuple can be returned?
|  |  How does a template allocator argument work if variable template arguments are used for values?
|  |  The problem is that you would mostly want the allocator to be an argument with a default value of the default allocator
|  |  Could the template argument be layed out as <key, value, allocator=default, values...>
|  |  Could the template arguments be side stepped by using a static make_ function instead of constructors
|


Return Values:
|  Use std::optional<> with operator[] ?
|  Use a custom struct that has operator bool() ?
|  |  Could have extra information such as how many values are in this key
|  Use operator() to get a specific value out of a key + tuple


Make untyped container with void* so that template bloat is minimal
|  Variable holds size in bytes
Use std::hash() ?
Save hash near reader count and pack them all together
Use power of 2 sizing


Does the number of readers need to be part of the block index in the new atomic lookup array?
|  If you lookup a block index, how do you know you haven't had it deleted from you?
|  Use 8 bits for readers, 24 bits for the index, and two special values for EMPTY and DELETED
|  Make START_SPECIALS = DELETED
|  Last thread out frees the block
|  |  Thread that sees readers == 1 && DELETED frees the block by setting the readers to 0 and the index to EMPTY 
|  |  thread should see readers == 0 and DELETED



If two indices are being swapped atomically, do they need the readers attached to them?
|  They couldn't be changed to DELETED or EMPTY underneath
|  They could however be changed to be completely different values with the same indices
|  While the swap could be done atomically, you don't know if that is what you want to do
|  |  Maybe there is a way for eventual consistency by checking before and after two indices are swapped
|  |  However this introduces the possibility of an inserted value blinking out of existence due to another thread seeing an EMPTY or DELETED slot too early
|  This means that the actual sequence is:
|  |  Readers need to be incremented
|  |  The hashes need to be checked to make sure that their positions need to be swapped
|  |  Swap the indices
|  |  Decrement the readers
|  This is all neccesary because an insertion needs to start from the first free slot and swap backwards until:
|  |  The hash lines up with it's natural slot (hash % slots) or ...
|  |  The element at one index less has the same hash
|  |  |  What if they have the same hash but not the same key? 
|  |  |  Whole other can of worms, maybe they should be compared with operator< etc.
|  


Value meta data:
|  Store the hash
|  Store the index in the meta data? - no need since you are literally reading from the index when you read the meta data - you have to have it saved as a variable on the stack locally already
|  Hash and what else since the size is constant?  
|  Does the hash need to be stored? 
|  |  Storing the hash could save time since robin hood hashing will be doing comparisons with the neighbor slots
|  Does the meta data need to be saved in a separate place?
|  Why was it done like that previously? Cache locality?
|  Should the hash and the key be stored together with the value stored separatly?

What happens if an index is deleted, cleaned up, then the same index is used again and moved to a different slot while another thread is reading?
|  If a Idx is moved around, it can still be searched for
|  If the readers is incremented, that val_idx can't be used again, so you know it is unique
|  Even if it is moved, you know that the key it contains can't change and thus the hash can't change
|  If the hash can't change, you can start from the natural/ideal slot position and search forward until you find the index you are looking for
|

Possibly need to make sure that when deleting a Idx in a slot, DELETED is set atomically, then separately the readers are decremented, and only if the deleting thread gets back readers == 1 and DELETED is it responsible for freeing the block
|  If readers == 1 and DELETED the Idx needs to be successfully compare and swapped for readers == 0 and DELETED before freeing the block
|  Need to increment the readers before marking for deletion, so that there isn't confusion about what thread needs to delete 
|  |  This sets up the case where a thread can get be the only one to comapre and swap from readers==1 && DELETED to readers==0 && DELETED
|


How to iterate through multiple values for a single key?
|  On step forward do multiple steps
|  |  Increment the reader count
|  |  Read the key and value into the iterator
|  |  Decrement the reader count
|  |  On dereference, return the value that was already read
|  |  If no value is found, set the iterator to == end()
|


Have to make room for the block list
|  A block list header
|  A u32 for each index
|  Should the current list index eventually be padded to be on its own cache line to negate false sharing?
| 


Capacity and the concurrent list
|  Might need to keep track of capacity atomically with the concurrent list
|  Instead of version in the head, a u32 can be used for capacity 
|  Keeping track of capacity is important so that a resize can be done before reaching the end of the list

Freeing a linked list of indices all at once
|  There might not be an oportunity to free a linked list of indices instead of a single index
|  If there is a small thread local cache of indices, using a bulk free could become more plausible
|  


Concurrent List
|  Does the concurrent list need to keep the version number 
|  ABA problem exists in the form of the index under the compare and swap being the same, but the index in the cell/slot it references has changed
|  If 24 bits are all that is needed for the indices, at least the versions can have 8 more bits
|  24 bits for idx, 40 bits for version
|  40 bits gives a little over 1 trillion versions
|

Using as unordered_set, unordered_map, and unordered_multimap
|  Give values as a variadic template
|  Let the variadic type arguments that make up values be zero or more values
|  This will give a unified set, multi-set, map and multi-map
|  All with a multiple types, creating a table
|  Still not sorted so can't query ranges
|  Can still only use 1 key
|  |  Could this be changed using a variadic template for keys?
|  |  How would construction work? Would it need to be compound?
|  |  Ordering could get tricky - maybe the first key would need to be primary and other keys would jump to index that only contains the real index to jump to
|  Does boost's nightmare multi-index map enable lookup using multiple different key types as keys?
|  |  Yes, it enables one or more indices

Simplifying construction
|  Use tuples as lists of types?
|  Make or copy a simple list of types 
|  Should the choice of multiple values be left up to the user since they can use a tuple<> themselves?
|  Would a make_flf_map function be more elegant for custom allocators?
|  How should arbitrary memory like shared memory mapped files work? anothe make_ function?
|  |  might need malloc and free 
|  |  don't need realloc, because resizing will make a second buffer so that reading is always available

Should 8 bytes be left after sizeBytes for a type number?
|  Would this help, even in the case of LAVA?


Keeping track of size:
|  Can the size be incremented atomically but separatly from the ListHead ?
|  It would be serial and eventually consistent, but not in lock step with the ListHead Index and version
|  ListHead is isolated and could potentially be 128 bits instead of 64 bits
|


operator[] and operator()
|  Will these need to return a smaller struct / iterator that does the actual insert on operator= assignment?
|  

Robin Hood Insertion
|  what if the span of ideal slots changes while inserting
|  |  while inserting into a slot/cell, 
|  |  probe forward and find an empty slot
|  |  compare and swap sucessfully
|  |  meanwhile the span of slots before it has changed, and now the slot being inserted ends a span of another key
|  |  will need to check the previous slot at the same time as the current slot to make sure that it is in the correct key span
|  |  |  this will mean incrementing the readers of both, 
|  |  |  then checking their values
|  |  |  then potentially swapping them
|  |  |  then decrementing their values
|  Can a deleted slot get swapped? 
|  |  only after the thread owning deletion sets it to DELETED and readers to 0
|  |  what is important is that the DELETED slot doesn't change to EMPTY until the readers are 0
|  |  because of this, a DELETED slot can't be moved, because any reading thread needs to come back to that specific index to decrement its readers
|  |  the thread that sets it to DELETED and readers==0 will then need to swap it forward until it finds an EMPTY slot
|  |  when the deleting thread finds the EMPTY slot as the next slot, it will try to compare and swap them both to EMPTY
|  Big win for robin hood hashing is that finding a key that is not in the table has a very early exit
|  
|

Alignment
|  Might need to make the header contain padding for alignment 
|  There could be an offset parameter after the other parameters that says where the per element memory should start
|  This could ensure that alignments such as cache line specific variables and 128 bit aligned atomic operations are in place  
|

Initial capacity
|  Should the initial capacity be 8 or 16?
|  It could be argued that there is no reason to use a hash table for fewer elements since they could be searched linearly
|


Insertion
|  Need to figure out what will have to happen in insertion
|  It is possible that the insertion start will be an EMPTY slot at the end of different span than the inserting key
|  It is possible that other indices closer to the ideal position will be moved around
|  Is it possible that the inserting Key will be moved by another thread before it is in its ideal position?
|  |  Yes, because DELETED slots/cells will get bubbled forward until they find an EMPTY slot
|  |  A thread can be inserting a key and find that the key is no longer where it put it
|  |  It will have to loop towards the ideal position to find it 
|  |  It can then keep trying to swap it towards it's ideal position, also stopping if it hits a Key that is further or the same distance from its ideal position
|  What if a value is being inserted and ends up bumping up against another value when there is an EMPTY block breaking up the span
|  |  Is it actually possible? Yes if they are written to an EMPTY slot and in between finding it and writing to it other slots are deleted 
|  |  Does there need to be a special value for a index that is currently being inserted? 
|  |  |  maybe the index with readers set to 255/max, using max readers as a special value? 
|  |  |  then there would be one less possible reader, but that slot could be uniquely identified by it's index, and as mid-insertion
|  |  When finding a value behind the slot a thread is trying to insert, it could use recursion to make sure that value does not have any behind it
|  |  |  Does this situation need to be moot/impossible? 
|  |  |  Does a thread just need to check if there is an EMPTY in the span after inserting and restart the insertion if it finds one closer?
|  |  Recursive checking for EMPTY is one way, since once a span is created that contains the index being inserted, that span should not be broken by an EMPTY slot (DELETED should be swapped up until hitting an EMPTY)
|  |  Can't start from the beggining of the span, because that would blink other indices out of existence as they are swapped
|  |  Does deletion need to swap the DELETED with the EMPTY it finds so that it can move elements in the middle of insertion down? would this mean potentially looping through the whole array?
|  |  Does insertion need to read a pair of indices so that it never starts with a stray EMPTY to the left?
|  |  |  This might be the solution to spans breaking under multiple indices being inserted
|  |  |  Does this imply that a recursive function needs to follow the DELETED index until it is set to EMPTY?
|  |  |  While DELETED is going to always be part of a span, it might not always be part of the current index's span
|  |  |  If inserting, does an EMPTY slot with a real slot before it need to be found?
|  |  |  If a DELETED is in the way, try to be the thread that sets it to EMPTY 
|  |  |  Thread that is doing the DELETING will find that it is not there and look forward for it since DELETED slots can only go forward
|  |  |  The deleting thread will then find the empty slots and know that it has been taken over

Find / Get
|  What are the conditions for stopping a find?
|  |  Can't stop on finding something further from its ideal position (further than what?)
|  |  Can stop if hitting an EMPTY slot/cell
|  |  Can stop if the current cell is closer to it's ideal position than the number of indices searched? 
|  |  If the slot being checked has an ideal position forward from the ideal position of the Key being searched for, that should mean they Key isn't found
|
|

List versioning:
|  Can the version be combined with the next index?
|  If the version and next index are split into separate bit fields anyway can they be one number?
|  Maybe the best solution is to simply increment the version only when the index be swapped in is less or equal to the previous index
|  Since the ABA problem is really a problem of not knowing about wrap around, the version only needs to be there from wrap around
|  Would caching 8 or so indices per thread help with versioning less?
|  |  If reading from the 8 indices in the cache, would the versioning be avoided?
|  |  Would need to also make sure to destruct the thread local array of 8 indices so that they are returned to the list on thread exit
|  Are there other options to avoid versioning or version roll over?
|  |  On version rollover should it be locked in the same way as whatever the re-allocation ends up being?
|  |  Should a thread grabbing an index from the list check if the next index is going to move backwards?
|  |  |  Try to grab that index repeating up to a set amount of times (somewhere in the range 4 - 128) 
|  |  |  Grab indices while they are lower than the first index grabbed, up to set amount, or until you get to the 0 index
|  |  |  Sort the now owned indices, take the lowest and insert the rest in one compare and swap
|  |  |  With more indices ascending, the version should be needed less often
|  |  |  This would also increment the version but reset the list index further back
|  |  |  It would come at the expense of consistent insertion time 
|  |  
|  Does the value also need to contain the version before or after the hash?
|  |  This would give the ability to know if an index is the same, but not atomically


Decrementing Readers
|  If underlying indices have moved, they will have to be found
|  Indices can move backwards if an index before them is deleted
|  Indices can move forward if they are bumped up by indices further from their ideal slot
|


Dealing with the first and last slots:
|  Can't swap the first and last slots atomically
|  Review simdb notes
|  Possibly make a " -1 " slot and a slot after the end 
|  How can the extra slots be used?
|  What are the problems that might be faced?  
|  |  DELETED at the end might not know if it is up against EMPTY atomically
|  |  placing an index at the first index can't atomically know that it has reached its native span
|  Can the ends be versioned?
|  Can the ends be AB swapped? 
|  Should the ends be 128 bit aligned so that they can have versions integrated with two u32 Idx structs? 
|  |  Then the versions could be synced between the two slots so they are known to be the same
|  What if there is only one thread allowed to deal with the ends  
|  |  Could be synced with a separate atomic variable
|  |  Can one thread clean up the state of both ends?
|  |  If one thread does not aquire the end slots boolean are there scenarios where other threads aren't going to be able to clean up the state? 
|  If there are only 254 threads possible, shouldn't there be only 254 indices being inserted at one time ?
|  |  If immediate availability is given up, a stack of 254 units could be used to queue up indices that still need to be inserted
|  |  This could be used for only indices that need to be swapped around the ends AND don't get the atomic end point boolean
|  Maybe a spinlock or mutex just for swapping the ends wouldn't be so bad 
|  |  If there was a spinlock, it could also check the indices in both end slots while it spins
|  Could the end slot be treated as a vector of elements? 
|  |  The table memory could be expanded to accomodate elements off the end
|  |  The end could be expanded by 2x each time
|  |  If the end gets to a certain size relative to the rest of the table, the table can be resized
|  |  This should place each of the spans leading into the end in different locations

 
Re-allocating memory
|  Should there be an 8 bytes slot for a previous table
|  when atomically swapped, writes continue on the new table and failed reads can also check the old table
|  once all members have been copied and deleted from the old table, atomically set it to nullptr/0 


Clean Deleted Function
|  Can't find a specific DELETED slot 
|  Make function to recursivly move any DELETED slots from a span from a certain point forward 
|  If two deleted slots are found in a row, needs to save the position of the first and try to remove the second by calling a recursive function
|  Also could use a 254 u32 stack structure residing in stack memory to remember previous points to restart from?

PlaceIdx Function
|  Needs to act like DELETED function except it will try to move LIVE indices towards their ideal positions recursivly

SortPair Function
|  Can take a range of slots, usually from the slot an index was put in, to the it's ideal position
|  If there is pair of two live or two deleted indices, do a recursive call with a smaller range
|  resume from the blocked index on the recursive function return
|  DELETED needs to go until it finds EMPTY or at least until it is moved to another span
|  One pass should be enough to guarantee an inserted index is moved into its span since the index should only move closer to its ideal position
|  Ends dealt with by having extra slots off the end 
|

Moving Readers
|  move reader count from the value index array to the actual value struct
|  instead of a hash-key-value struct, now have a readers-hash-key-value struct 
|  number of indices can change to 32 bit instead of 24 bit - 4 billion instead of 16 million
|  when you jump back to the value index array after incrementing the read variable, you still know that the index is the same
|  because you increment the readers and haven't yet decremented it, that index can't be deallocated, returned to the list, and ultimatly repurposed
|  becaues the index can't be repurposed while readers is positive, if you find it again in the val_idx array, it must be pointing to the same key you just compared
|  How does this effect sorting?
|  |  DELETED should always be swapped to the right until it finds an EMPTY
|  |  DELETED can be swapped without looking at readers, hashes, or keys
|  |  value indices need an INSERTED flag so they will actually be 31 bits / 2 billion indices
|  |  when sorting, indices will have their readers incremented, their hashes read to find ideal positions, and then be compare and swapped
|  |  if the comapre and swap fails, check the current val_idxs and decrement the readers for either that are missing from the previous try
|





