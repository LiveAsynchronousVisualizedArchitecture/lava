

Should data flow nodes have a separate function from the main that runs first?
 - Gives the number of allocations along with each of their sizes
 - Then one thread local allocation could be done
 - Would be difficult for larger nodes to give the maximum amount of memory needed if they had the potential to re-use memory.


Is scatter needed?
 - The real synchronization should come from data
 - Ordering can be done at any point by sorting on the version number
 - any list should be able to be 'scattered' and processed by different threads because the data is separate


Make message passing nodes circles and data flow containers squares
 | both could contain stats
 | the message passing nodes could have segments on the border that show their connections/messages to data flow containers and other message nodes
 | | use an arc along the border and change it to hav a teardrop shaped protrusion that transitions into the line/noodle showing the connection?




Can there be a node that enables shared memory parallelism like openMP?
|  Need an init() method that looks at the input and allocates memory for the output 
|  |  Will this need to use global memory allocation like malloc, jemalloc, or rpmalloc?
|  Need a method to get the next section of memory to operate on, possibly just needs to increment an ID atomically
|  Should this only be a node that creates multiple packets that contain all that is needed for other nodes to use shared memory parallelism?
|  |  Would need to be an actual memory address to non-thread local memory
|  |  Need to have a flag saying that it is a memory address and not an index
|  |  Need to contain the global memory address, the ID for what section this packet is for and a way to reference count the global address so it can be freed?
|  |  Would want a tbl with it that would contain parameters for how to use the memory and the ID (like image dimensions)




Node Types
|  how to handle constant inputs
|  |  should each node have a potential tbl of constants?
|  |  this would mean the first argument could be a tbl/pointer to the table memory
|  |  when using the node graph, the table could be output as a .h file and compiled into the shared library 
|  |  the constants tbl could be passed into the node function or use an implicit pointer


Accumulator / General loop and iteration 
|  Should there be a specific accumulator node? 
|  Can accumulation of the output with new inputs be done with:
|  |  Nodes able to take optional arguments
|  |  A node that takes a list and an optional argument to inject into that list
|  |  The ability to make circular references in the graph
|  Does the ability to make circular references depend on either branching, optional arguments or both so that there is a way to break out of the loop? 
|  |  accumulation could be done with a branching node before the accumulator node 
|  |  the branch bypasses the accumulator if there is only one packet in the list
|  |  if there is more than one packet, the branch goes to the accumulator
|  |  the accumulator's output would go back in to the branch   -------the branch node's single packet path and the accumulator's output path go to some node with two optional inputs - could even be another accumulator node
|  |  the branch would need two inputs to collect all the packets - if there is only one it bypasses the accumulator, if there are multiple, it feeds them into the accumulator


Ordering
|  Should all data packets be dealt with before going back to the message nodes?
|  Should it be done in an interlaced way to keep message passing nodes from lagging?
|  Should there be generator nodes and message passing nodes, or just message nodes?
|  Does the frame number need to be specific to each message node? Instead of frame number, a frame + msg node combination


Concurrency with flow node types
|  Revisit original node type ideas and see how they line up with the current packet method
|  If there are lists being output, does a dedicated split node need to exist?
|  If every input can potentially be a list is a gather node needed? 
|  If a split can be automatically parallized, that could imply that all each node is run with only one packet from a list
|  The flip side is entire lists being passed in automatically and splitting/parallelism done manually
|  Automatic parallelism whenever it is possible may be a better bet than expecting anyone to manually choose a special split node or split node attribute. 
|  A special gather node or gather node attribute to combine a list seems more reasonable because it makes parallelism automatic and the exceptional case of a gather node neccesary 
|  If a gather node is the manual route neccesary, tools and error messages can help the learning curve. 
|  Will message nodes need to take lists in their entirety? 
|  Should there be something in between a full gather and a node that only takes single packets? 
|  A "Take" node that can take as many or as few packets for each slot as it wants?  First call returns the number of packets the Take node wants.

Concurrency with data structures inside LavaFlow 
|  Likely will need a resizable array of atomic variables
|  Look back at atomic vector / atomic array and make it double buffered so that it can be resized without locking


Should the function passed be one that inserts a buffer instead of a simple allocation function?
|  The decision to place the output in memory would then be done in the flow loop
|  The output would then be placed directly into the db instead of copied to memory and copied to the db
|  If the output function needs to copy straight from a buffer anyway, would that happen no matter what? 
|  What happens with Cereal?
|  |  Cereal uses an archive object so a custom archive object could concievably be created
|  |  However it seems that likely there would be a serialization step and a copying step
|  |  A function that could potentially copy straight into the db would still save a copy
|  Should there be a tbl flatten function that 
|  Should a lava alloc function and allocator always be used so that if the db isn't needed there is potentially no copy?
|  |  does this take it back to the same place of always allocating memory and letting the loop store in the db if neccesary?


